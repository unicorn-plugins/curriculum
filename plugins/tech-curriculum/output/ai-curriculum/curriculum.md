# 생성형 AI 어플리케이션 개발 세부 커리큘럼

> 작성일: 2026-02-14
> 기본과정 3일(24시간) + 심화과정 4일(32시간) | 일 8시간 기준

---

# PART 1. 기본과정 (3일, 24시간)

---

## Day 1. AI 어플리케이션 기초 (8시간)

### 모듈 1-1. 생성형 AI 개요와 개발환경 구축 (2시간)

**학습 주제**: 생성형 AI의 현재와 개발 준비
**학습 목표**:
- 생성형 AI의 발전 흐름과 LLM의 동작 원리를 개략적으로 설명할 수 있다
- Python 기반 AI 개발환경을 독립적으로 구축할 수 있다
- API 키를 안전하게 관리하는 방법을 실천할 수 있다

**세부 학습 내용**:

| 시간 | 구분 | 내용 |
|------|------|------|
| 30분 | 이론 | 생성형 AI 개요: 전통 AI vs 생성형 AI, LLM의 탄생과 발전(GPT, Claude, Gemini), Transformer 아키텍처 핵심 직관 |
| 20분 | 이론 | 토큰과 컨텍스트 윈도우: 토큰화 원리, 컨텍스트 윈도우 크기의 의미, 비용 구조 이해 |
| 10분 | 이론 | 개발환경 아키텍처: Python + venv + API 키 관리(.env) + Jupyter Notebook 구성도 |
| 40분 | 실습 | [Lab 1-1] 개발환경 구축: Python 가상환경 생성, openai/anthropic 패키지 설치, .env 파일 설정, API 연결 테스트 |
| 20분 | 실습 | [Lab 1-2] 토큰 탐색기: tiktoken을 활용한 토큰 분석, 한글 vs 영문 토큰 수 비교, 비용 계산 실습 |

**평가**: Lab 1-1 환경 구축 완료 확인 + Lab 1-2 토큰 분석 결과 제출

---

### 모듈 1-2. LLM API 기초와 프롬프트 엔지니어링 (3시간)

**학습 주제**: LLM API 호출의 기본 구조와 프롬프트 설계
**학습 목표**:
- Chat Completions API의 요청/응답 구조를 정확히 이해하고 호출할 수 있다
- System/User/Assistant 메시지 역할을 구분하여 활용할 수 있다
- Temperature, Top-p 등 모델 파라미터가 출력에 미치는 영향을 실험적으로 확인할 수 있다

**세부 학습 내용**:

| 시간 | 구분 | 내용 |
|------|------|------|
| 30분 | 이론 | Chat Completions API 구조: 요청 형식(model, messages, parameters), 응답 구조(choices, usage), HTTP 통신 흐름 |
| 20분 | 이론 | 메시지 역할 체계: system(페르소나 설정), user(질문), assistant(응답), 역할 조합의 효과 |
| 20분 | 이론 | 모델 파라미터 심화: temperature(창의성), top_p(다양성), max_tokens(길이), frequency/presence_penalty(반복 제어) |
| 40분 | 실습 | [Lab 1-3] 첫 번째 API 호출: "Hello, AI!" 기본 호출, 응답 파싱, 에러 핸들링(rate limit, timeout) |
| 30분 | 실습 | [Lab 1-4] 파라미터 실험실: 동일 프롬프트에 temperature 0.0/0.5/1.0 적용, 출력 비교 분석표 작성 |
| 40분 | 실습 | [Lab 1-5] 프롬프트 엔지니어링 워크숍: Zero-shot, Few-shot, Chain-of-Thought 기법 비교 실습, 실무 프롬프트 3종 작성 |

**평가**: Lab 1-5 프롬프트 3종 결과물 제출 + 파라미터 비교 분석표 제출

---

### 모듈 1-3. 멀티턴 대화 시스템 구현 (2시간)

**학습 주제**: 대화 맥락을 유지하는 챗봇 구현
**학습 목표**:
- 멀티턴 대화에서 메시지 히스토리 관리의 원리를 이해한다
- 컨텍스트 윈도우 제한 내에서 효율적인 대화 관리 전략을 구현할 수 있다
- 스트리밍 응답을 활용한 실시간 대화 인터페이스를 구현할 수 있다

**세부 학습 내용**:

| 시간 | 구분 | 내용 |
|------|------|------|
| 20분 | 이론 | 멀티턴 대화 원리: Stateless API에서 맥락 유지 방법, 메시지 히스토리 구조, 슬라이딩 윈도우 전략 |
| 10분 | 이론 | 스트리밍 응답: SSE(Server-Sent Events) 방식, 청크 단위 수신, UX 개선 효과 |
| 50분 | 실습 | [Lab 1-6] 대화형 챗봇 구현: 메시지 리스트 관리, 대화 루프 구현, 히스토리 길이 제한(최근 N턴), 스트리밍 출력 |
| 40분 | 실습 | [Lab 1-7] 역할극 챗봇: system 프롬프트로 특정 캐릭터/전문가 페르소나 부여, 대화 품질 비교 |

**평가**: Lab 1-7 역할극 챗봇 시연 + 코드 제출

---

### 모듈 1-4. Day 1 리뷰 (1시간)

| 시간 | 구분 | 내용 |
|------|------|------|
| 20분 | 퀴즈 | Day 1 핵심 개념 확인 퀴즈 (10문항): 토큰, 파라미터, 메시지 역할, 멀티턴 구조 |
| 20분 | 리뷰 | 실습 결과 공유 및 피드백, 공통 오류 패턴 정리 |
| 20분 | 안내 | Day 2 예습 포인트 안내, Q&A |

---

## Day 2. 문서 처리와 음성 AI (8시간)

### 모듈 2-1. 문서 요약과 텍스트 분석 (2.5시간)

**학습 주제**: LLM을 활용한 문서 요약 및 구조화된 텍스트 분석
**학습 목표**:
- 긴 문서를 청크 단위로 분할하여 요약하는 전략을 구현할 수 있다
- Map-Reduce 패턴을 활용한 대규모 문서 처리 방법을 이해한다
- JSON 모드를 활용하여 구조화된 출력을 생성할 수 있다

**세부 학습 내용**:

| 시간 | 구분 | 내용 |
|------|------|------|
| 25분 | 이론 | 문서 요약 전략: 단일 패스 vs 분할 요약, Map-Reduce 패턴, Refine 패턴, 각 전략의 트레이드오프 |
| 15분 | 이론 | 구조화된 출력: JSON 모드 활용, 출력 스키마 설계, 파싱 안정성 확보 |
| 50분 | 실습 | [Lab 2-1] 문서 요약기: 긴 텍스트 청크 분할, 청크별 요약 생성, 최종 통합 요약 작성 |
| 40분 | 실습 | [Lab 2-2] 구조화된 분석기: 뉴스 기사 입력 -> JSON 형식 분석 결과(주제, 감성, 핵심 키워드, 요약) 자동 추출 |

**평가**: Lab 2-2 구조화된 분석 결과 JSON 제출

---

### 모듈 2-2. PDF 문서 처리 (2시간)

**학습 주제**: PDF 파싱과 LLM 기반 문서 Q&A
**학습 목표**:
- PDF에서 텍스트를 추출하고 전처리하는 파이프라인을 구축할 수 있다
- 추출된 텍스트를 기반으로 간단한 문서 Q&A 시스템을 구현할 수 있다
- 표, 이미지 등 복합 요소가 포함된 PDF 처리 전략을 이해한다

**세부 학습 내용**:

| 시간 | 구분 | 내용 |
|------|------|------|
| 20분 | 이론 | PDF 처리 파이프라인: PyMuPDF/pdfplumber 라이브러리, 텍스트 추출 전략, 표 데이터 처리, 레이아웃 보존 |
| 10분 | 이론 | 문서 Q&A 아키텍처: 컨텍스트 주입 방식, 프롬프트에 문서 내용 삽입, 한계와 RAG로의 발전 방향 |
| 50분 | 실습 | [Lab 2-3] PDF 텍스트 추출기: PDF 파싱, 페이지별 텍스트 추출, 전처리(불필요 문자 제거, 단락 재구성) |
| 40분 | 실습 | [Lab 2-4] PDF Q&A 챗봇: 추출된 텍스트를 컨텍스트로 활용, 사용자 질문에 대한 문서 기반 응답 생성 |

**평가**: Lab 2-4 PDF Q&A 챗봇 시연 (지정 PDF에 대한 질의응답 3건)

---

### 모듈 2-3. 음성 AI: STT와 TTS (2.5시간)

**학습 주제**: 음성 인식(STT)과 음성 합성(TTS)을 활용한 AI 어플리케이션
**학습 목표**:
- Whisper API를 활용하여 음성을 텍스트로 변환할 수 있다
- TTS API를 활용하여 텍스트를 자연스러운 음성으로 합성할 수 있다
- STT + LLM + TTS를 연결한 음성 대화 파이프라인을 구현할 수 있다

**세부 학습 내용**:

| 시간 | 구분 | 내용 |
|------|------|------|
| 20분 | 이론 | STT 기술 개요: Whisper 모델 아키텍처 직관, 지원 언어, 오디오 형식, 정확도 영향 요소 |
| 15분 | 이론 | TTS 기술 개요: 음성 합성 원리, 사용 가능한 음성 모델, 음성 파라미터(속도, 음색) |
| 15분 | 이론 | 음성 파이프라인 설계: STT -> LLM 처리 -> TTS 연결 아키텍처, 지연시간 최적화 |
| 40분 | 실습 | [Lab 2-5] 음성 텍스트 변환: Whisper API로 오디오 파일 전사, 타임스탬프 추출, 다국어 음성 처리 |
| 30분 | 실습 | [Lab 2-6] 텍스트 음성 합성: TTS API로 텍스트를 음성 파일로 변환, 다양한 음성/속도 옵션 비교 |
| 30분 | 실습 | [Lab 2-7] 음성 대화 파이프라인: STT -> 질문 이해 -> LLM 응답 생성 -> TTS 출력의 전체 흐름 구현 |

**평가**: Lab 2-7 음성 대화 파이프라인 시연

---

### 모듈 2-4. Day 2 리뷰 (1시간)

| 시간 | 구분 | 내용 |
|------|------|------|
| 20분 | 퀴즈 | Day 2 핵심 개념 확인 퀴즈 (8문항): 문서 요약 전략, PDF 처리, STT/TTS 파이프라인 |
| 20분 | 리뷰 | [비즈니스 적용 토론] "AI 회의록 자동화" 시나리오: STT + 요약 + 액션아이템 추출 설계 토론 |
| 20분 | 안내 | Day 3 예습 포인트 안내, Q&A |

---

## Day 3. 비전 AI와 Local LLM, 기본과정 종합 (8시간)

### 모듈 3-1. VLM: 비전-언어 모델 활용 (2.5시간)

**학습 주제**: 이미지를 이해하는 멀티모달 AI 어플리케이션
**학습 목표**:
- Vision API를 활용하여 이미지 분석 요청을 구성하고 호출할 수 있다
- 이미지 기반 Q&A, 설명 생성, OCR 대안 등 다양한 활용 패턴을 구현할 수 있다
- 이미지 입력의 토큰 비용과 해상도 전략을 이해한다

**세부 학습 내용**:

| 시간 | 구분 | 내용 |
|------|------|------|
| 25분 | 이론 | VLM 개요: 비전-언어 모델의 동작 원리, 이미지 토큰화, 해상도별 비용, 지원 이미지 형식 |
| 15분 | 이론 | 활용 패턴: 이미지 설명, 비교 분석, 텍스트 추출(OCR 대안), 차트/그래프 해석, 코드 스크린샷 분석 |
| 40분 | 실습 | [Lab 3-1] 이미지 분석기: 이미지 URL/Base64 인코딩 입력, 상세 설명 생성, 다양한 프롬프트 기법 적용 |
| 30분 | 실습 | [Lab 3-2] 멀티 이미지 비교: 복수 이미지 동시 입력, 차이점 분석, 비교 리포트 자동 생성 |
| 40분 | 실습 | [Lab 3-3] 비전 기반 OCR 대안: 문서 사진에서 텍스트 추출, 명함/영수증 정보 구조화 |

**평가**: Lab 3-3 비전 OCR 구조화 결과 제출

---

### 모듈 3-2. Local LLM 구축과 활용 (2.5시간)

**학습 주제**: 로컬 환경에서 LLM 실행하기
**학습 목표**:
- Ollama를 활용하여 로컬 LLM을 설치하고 실행할 수 있다
- Cloud LLM과 Local LLM의 성능, 비용, 보안 측면을 비교하여 적합한 상황을 판단할 수 있다
- 로컬 LLM에 OpenAI 호환 API를 적용하여 기존 코드를 재활용할 수 있다

**세부 학습 내용**:

| 시간 | 구분 | 내용 |
|------|------|------|
| 25분 | 이론 | Local LLM 개요: 필요성(보안, 비용, 오프라인), Ollama/llama.cpp 생태계, 양자화(Quantization) 개념, 하드웨어 요구사항 |
| 15분 | 이론 | Cloud vs Local 의사결정 프레임워크: 성능, 비용, 지연시간, 보안, 커스터마이징 5축 비교 |
| 10분 | 이론 | OpenAI 호환 API: 로컬 LLM을 Cloud API와 동일한 인터페이스로 사용, base_url 변경만으로 전환 |
| 40분 | 실습 | [Lab 3-4] Ollama 설치와 모델 실행: Ollama 설치, 모델 다운로드(llama3, gemma2 등), CLI 대화 테스트 |
| 30분 | 실습 | [Lab 3-5] OpenAI 호환 API 활용: Ollama의 OpenAI 호환 엔드포인트로 기존 코드 재활용, Cloud/Local 전환 실습 |
| 30분 | 실습 | [Lab 3-6] Cloud vs Local 벤치마크: 동일 프롬프트에 대한 Cloud/Local 응답 품질, 속도, 비용 비교표 작성 |

**평가**: Lab 3-6 벤치마크 비교표 제출 + Cloud vs Local 선택 기준 서술

---

### 모듈 3-3. 기본과정 종합 프로젝트 (2시간)

**학습 주제**: 기본과정 학습 내용을 통합한 미니 프로젝트
**학습 목표**:
- 기본과정에서 학습한 기술 요소를 조합하여 하나의 완성된 어플리케이션을 구현할 수 있다
- 요구사항 분석, 아키텍처 설계, 구현, 테스트의 전체 흐름을 경험한다

**프로젝트 선택지** (1개 선택):

| 프로젝트 | 활용 기술 | 난이도 |
|----------|-----------|--------|
| A. AI 회의록 자동화 시스템 | STT + 요약 + JSON 구조화 | 중 |
| B. 문서 Q&A 도우미 | PDF 처리 + 멀티턴 대화 + 스트리밍 | 중 |
| C. 멀티모달 리포트 생성기 | VLM + 문서 요약 + TTS 출력 | 상 |

**세부 진행**:

| 시간 | 구분 | 내용 |
|------|------|------|
| 10분 | 안내 | 프로젝트 선택 및 요구사항 확인 |
| 80분 | 실습 | [종합 Lab] 프로젝트 구현: 아키텍처 설계 -> 핵심 기능 구현 -> 통합 테스트 |
| 30분 | 발표 | 팀/개인별 결과물 시연 및 상호 피드백 |

**평가**: 종합 프로젝트 완성도(동작 여부 50% + 코드 품질 30% + 발표 20%)

---

### 모듈 3-4. Day 3 리뷰 및 기본과정 마무리 (1시간)

| 시간 | 구분 | 내용 |
|------|------|------|
| 15분 | 퀴즈 | Day 3 핵심 개념 확인 퀴즈 (8문항): VLM, Local LLM, Cloud vs Local |
| 25분 | 리뷰 | 기본과정 3일간 학습 내용 종합 정리, 핵심 키워드 맵 완성 |
| 20분 | 안내 | 심화과정 안내, 사전 준비사항 공유, 수료 피드백 수집 |

---

# PART 2. 심화과정 (4일, 32시간)

---

## Day 1. 도구 연동과 프레임워크 (8시간)

### 모듈 4-1. Function Calling: LLM에 도구를 연결하다 (3.5시간)

**학습 주제**: LLM이 외부 도구를 호출하는 Function Calling 메커니즘
**학습 목표**:
- Function Calling의 동작 원리(도구 정의 -> 모델 판단 -> 함수 실행 -> 결과 반환)를 정확히 설명할 수 있다
- 단일/복수/병렬 Function Call을 구현하고 실행 흐름을 제어할 수 있다
- 실무에서 자주 쓰이는 도구 패턴(날씨, 검색, DB 조회, 계산)을 구현할 수 있다

**세부 학습 내용**:

| 시간 | 구분 | 내용 |
|------|------|------|
| 30분 | 이론 | Function Calling 동기부여: "왜 LLM에 도구가 필요한가?" - LLM의 한계(실시간 데이터, 계산, 외부 시스템), 도구 연동으로 극복 |
| 20분 | 이론 | 동작 메커니즘: tools 파라미터 정의(JSON Schema), 모델의 도구 선택 판단, tool_choice 옵션, 실행 루프 |
| 10분 | 이론 | 고급 패턴: 병렬 호출(Parallel Function Calling), 중첩 호출, 에러 핸들링, 안전한 함수 실행 |
| 40분 | 실습 | [Lab 4-1] 첫 번째 Function Call: 날씨 조회 함수 정의, API 호출, 결과 반환 루프 구현 |
| 30분 | 실습 | [Lab 4-2] 복수 도구 연동: 날씨 + 환율 + 뉴스 검색 3개 도구 등록, 자연어 질문에 따른 자동 도구 선택 |
| 40분 | 실습 | [Lab 4-3] 병렬 Function Call: 여러 도시 날씨 동시 조회, 병렬 호출 감지 및 처리, 결과 통합 응답 생성 |
| 40분 | 실습 | [Lab 4-4] 실무 도구 챗봇: DB 조회 + 계산 + 외부 API를 조합한 비즈니스 어시스턴트 구현 |

**평가**: Lab 4-4 실무 도구 챗봇 시연 (3가지 이상 도구 연동 동작 확인)

---

### 모듈 4-2. LangChain 기초와 체인 구성 (3.5시간)

**학습 주제**: LangChain 프레임워크를 활용한 LLM 어플리케이션 개발
**학습 목표**:
- LangChain의 핵심 컴포넌트(Model, Prompt, OutputParser, Chain)를 이해하고 활용할 수 있다
- LCEL(LangChain Expression Language)을 사용하여 체인을 선언적으로 구성할 수 있다
- LangChain 기반 대화형 어플리케이션을 구축할 수 있다

**세부 학습 내용**:

| 시간 | 구분 | 내용 |
|------|------|------|
| 25분 | 이론 | LangChain 생태계 개요: 왜 프레임워크가 필요한가, 핵심 모듈(Models, Prompts, Chains, Memory, Agents), 아키텍처 |
| 15분 | 이론 | LCEL 소개: 파이프 연산자(\|)를 활용한 선언적 체인 구성, Runnable 인터페이스, 배치/스트리밍 지원 |
| 20분 | 이론 | Memory와 대화 관리: ConversationBufferMemory, ConversationSummaryMemory, 맥락 유지 전략 |
| 40분 | 실습 | [Lab 4-5] LangChain 첫걸음: ChatModel + PromptTemplate + OutputParser 조합, LCEL 파이프라인 구성 |
| 30분 | 실습 | [Lab 4-6] 체인 조합: SequentialChain으로 번역 -> 요약 -> 감성분석 파이프라인 구축 |
| 40분 | 실습 | [Lab 4-7] 대화형 체인: Memory를 활용한 맥락 유지 대화 시스템, 대화 요약 자동 생성 |
| 40분 | 실습 | [Lab 4-8] LangChain + Function Calling 통합: LangChain Agent로 도구 연동 챗봇 업그레이드 |

**평가**: Lab 4-8 LangChain Agent 챗봇 시연

---

### 모듈 4-3. Day 1 리뷰 (1시간)

| 시간 | 구분 | 내용 |
|------|------|------|
| 20분 | 퀴즈 | Day 1 핵심 개념 확인 퀴즈 (10문항): Function Calling 동작 흐름, LangChain 컴포넌트, LCEL 구성 |
| 20분 | 리뷰 | Function Calling vs LangChain Agent 비교 토론, 어떤 상황에서 어떤 접근법이 적합한가 |
| 20분 | 안내 | Day 2 RAG 예습 포인트 안내, Q&A |

---

## Day 2. RAG 구축과 튜닝 (8시간)

### 모듈 5-1. RAG 파이프라인 기초 (3시간)

**학습 주제**: Retrieval-Augmented Generation 아키텍처 이해와 구현
**학습 목표**:
- RAG의 동작 원리(인덱싱 -> 검색 -> 생성)를 정확히 설명할 수 있다
- 문서 로딩, 청킹, 임베딩, 벡터 저장의 전체 인덱싱 파이프라인을 구현할 수 있다
- 벡터 유사도 검색 기반 RAG Q&A 시스템을 구축할 수 있다

**세부 학습 내용**:

| 시간 | 구분 | 내용 |
|------|------|------|
| 25분 | 이론 | RAG 개요: LLM의 지식 한계, 왜 검색 증강이 필요한가, RAG 아키텍처(Indexing + Retrieval + Generation) |
| 20분 | 이론 | 인덱싱 파이프라인: 문서 로더(PDF, TXT, Web), 텍스트 분할(청킹 전략), 임베딩 모델(OpenAI, HuggingFace), 벡터 DB(Chroma, FAISS) |
| 15분 | 이론 | 검색과 생성: 유사도 검색(코사인 유사도), Top-K 검색, 프롬프트에 컨텍스트 주입, 답변 생성 |
| 50분 | 실습 | [Lab 5-1] RAG 인덱싱: PDF 문서 로드 -> RecursiveCharacterTextSplitter로 청킹 -> OpenAI 임베딩 -> ChromaDB 저장 |
| 30분 | 실습 | [Lab 5-2] RAG 검색과 생성: 사용자 질문 임베딩 -> 벡터 유사도 검색 -> 검색 결과 기반 답변 생성 |
| 40분 | 실습 | [Lab 5-3] LangChain RAG 체인: RetrievalQA 체인으로 RAG 시스템 구축, 소스 문서 표시 기능 추가 |

**평가**: Lab 5-3 RAG Q&A 시스템 시연 (지정 문서에 대한 질의응답 5건, 정확도 평가)

---

### 모듈 5-2. RAG 품질 튜닝 (2.5시간)

**학습 주제**: RAG 시스템의 검색 품질과 응답 품질 최적화
**학습 목표**:
- 청킹 전략(크기, 오버랩, 의미 기반)이 검색 품질에 미치는 영향을 실험적으로 확인할 수 있다
- 리랭킹(Reranking)과 하이브리드 검색으로 검색 정확도를 향상시킬 수 있다
- RAG 평가 지표(Faithfulness, Relevancy)를 이해하고 측정할 수 있다

**세부 학습 내용**:

| 시간 | 구분 | 내용 |
|------|------|------|
| 20분 | 이론 | 청킹 전략 심화: 고정 크기 vs 의미 기반 청킹, 오버랩 효과, 메타데이터 활용 |
| 15분 | 이론 | 검색 품질 향상: 키워드 검색(BM25) + 벡터 검색 = 하이브리드 검색, 리랭킹(Cross-Encoder), MMR(다양성) |
| 15분 | 이론 | RAG 평가: Faithfulness(답변의 근거 충실도), Answer Relevancy(질문 적합도), Context Precision(검색 정밀도) |
| 40분 | 실습 | [Lab 5-4] 청킹 실험실: 동일 문서에 chunk_size 200/500/1000, overlap 0/50/100 조합 적용, 검색 품질 비교 |
| 30분 | 실습 | [Lab 5-5] 하이브리드 검색: BM25 + 벡터 검색 앙상블, 리랭킹 적용, 검색 결과 Before/After 비교 |
| 30분 | 실습 | [Lab 5-6] RAG 품질 평가: 테스트 질문셋 준비, 답변 생성, Faithfulness/Relevancy 수동 평가표 작성 |

**평가**: Lab 5-6 RAG 품질 평가표 제출 (튜닝 전후 비교 포함)

---

### 모듈 5-3. 웹검색 통합 RAG (1.5시간)

**학습 주제**: 실시간 웹 정보를 활용하는 RAG 시스템
**학습 목표**:
- 웹 검색 API를 RAG 파이프라인에 통합할 수 있다
- 정적 문서 + 동적 웹검색을 조합한 하이브리드 RAG를 구현할 수 있다

**세부 학습 내용**:

| 시간 | 구분 | 내용 |
|------|------|------|
| 15분 | 이론 | 웹검색 통합 RAG: 정적 지식(벡터 DB) + 동적 지식(웹 검색)의 조합 아키텍처, 라우팅 전략 |
| 45분 | 실습 | [Lab 5-7] 웹검색 RAG: Tavily/Brave Search API 연동, 질문 유형에 따른 소스 자동 라우팅(문서 vs 웹) |
| 30분 | 실습 | [Lab 5-8] 통합 Q&A 시스템: 사내 문서 RAG + 웹 검색 결과를 통합한 종합 Q&A 봇 |

**평가**: Lab 5-8 통합 Q&A 봇 시연

---

### 모듈 5-4. Day 2 리뷰 (1시간)

| 시간 | 구분 | 내용 |
|------|------|------|
| 20분 | 퀴즈 | Day 2 핵심 개념 확인 퀴즈 (10문항): RAG 아키텍처, 청킹, 임베딩, 리랭킹, 하이브리드 검색 |
| 20분 | 리뷰 | [비즈니스 적용 토론] "사내 문서 Q&A 시스템" 설계: 실무 데이터로 RAG 구축 시 고려사항 토론 |
| 20분 | 안내 | Day 3 예습 포인트 안내, Q&A |

---

## Day 3. 고급 RAG와 에이전트 (8시간)

### 모듈 6-1. GraphRAG: 지식 그래프 기반 RAG (3시간)

**학습 주제**: 지식 그래프를 활용한 고급 RAG 아키텍처
**학습 목표**:
- 기존 벡터 RAG의 한계와 GraphRAG가 해결하는 문제를 설명할 수 있다
- LLM을 활용하여 텍스트에서 지식 그래프를 자동 구축할 수 있다
- 그래프 탐색 기반 검색으로 복잡한 관계형 질문에 답할 수 있다

**세부 학습 내용**:

| 시간 | 구분 | 내용 |
|------|------|------|
| 25분 | 이론 | GraphRAG 동기: 벡터 RAG의 한계(관계 정보 손실, 글로벌 질문 취약), 지식 그래프가 해결하는 문제 |
| 20분 | 이론 | GraphRAG 아키텍처: 엔티티 추출, 관계 추출, 커뮤니티 탐지, 글로벌/로컬 검색 전략 |
| 15분 | 이론 | 구현 도구: Neo4j 그래프 DB, LangChain GraphRAG 모듈, 시각화 도구 |
| 40분 | 실습 | [Lab 6-1] 지식 그래프 구축: LLM으로 텍스트에서 엔티티/관계 추출, 그래프 구조 생성 |
| 40분 | 실습 | [Lab 6-2] GraphRAG 검색: 그래프 탐색 쿼리 작성, 관계 기반 답변 생성, 벡터 RAG와 결과 비교 |
| 40분 | 실습 | [Lab 6-3] 하이브리드 GraphRAG: 벡터 검색 + 그래프 검색 결합, 질문 유형별 자동 라우팅 |

**평가**: Lab 6-3 하이브리드 GraphRAG 시연 (관계형 질문 3건에 대한 답변 품질 평가)

---

### 모듈 6-2. Multi-Agent System 설계와 구현 (4시간)

**학습 주제**: 여러 AI 에이전트가 협력하는 시스템 구축
**학습 목표**:
- Single Agent와 Multi-Agent System의 차이와 MAS가 필요한 상황을 판단할 수 있다
- 에이전트 역할 분담, 통신 패턴, 오케스트레이션 전략을 설계할 수 있다
- LangGraph를 활용하여 Multi-Agent 워크플로우를 구현할 수 있다

**세부 학습 내용**:

| 시간 | 구분 | 내용 |
|------|------|------|
| 20분 | 이론 | [워밍업] Single Agent vs Multi-Agent: 단일 에이전트의 한계, MAS의 장점(전문화, 병렬처리, 복잡도 분산) |
| 20분 | 이론 | MAS 아키텍처 패턴: Supervisor(관리자), Hierarchical(계층), Collaborative(협력), 역할 설계 원칙 |
| 20분 | 이론 | LangGraph 소개: 상태 그래프 개념, 노드(에이전트), 엣지(전환 조건), 조건부 라우팅, Human-in-the-loop |
| 30분 | 실습 | [역할 분담 설계 워크숍] 주어진 비즈니스 시나리오에 대해 에이전트 역할, 도구, 통신 흐름을 화이트보드에 설계 |
| 40분 | 실습 | [Lab 6-4] 첫 번째 MAS: LangGraph로 Researcher + Writer 2-에이전트 시스템 구현, 조사 -> 작성 파이프라인 |
| 40분 | 실습 | [Lab 6-5] Supervisor 패턴: 관리자 에이전트가 하위 에이전트(검색, 분석, 작성)에게 작업 분배, 결과 통합 |
| 50분 | 실습 | [Lab 6-6] 멀티에이전트 리서치봇: 웹 검색 에이전트 + 문서 분석 에이전트 + 리포트 작성 에이전트가 협력하는 리서치 시스템 구축 |

**평가**: Lab 6-6 멀티에이전트 리서치봇 시연 (주어진 주제에 대한 리서치 리포트 생성 확인)

---

### 모듈 6-3. Day 3 리뷰 (1시간)

| 시간 | 구분 | 내용 |
|------|------|------|
| 20분 | 퀴즈 | Day 3 핵심 개념 확인 퀴즈 (10문항): GraphRAG 구조, MAS 패턴, LangGraph 컴포넌트 |
| 20분 | 리뷰 | GraphRAG vs 벡터 RAG 적용 판단 기준 정리, MAS 설계 시 흔한 실수와 베스트 프랙티스 공유 |
| 20분 | 안내 | Day 4 최종 프로젝트 안내, 사전 준비사항 공유, Q&A |

---

## Day 4. 통합과 실무 적용 (8시간)

### 모듈 7-1. MCP: Model Context Protocol (2.5시간)

**학습 주제**: MCP를 활용한 표준화된 도구 통합
**학습 목표**:
- MCP의 개념과 Function Calling 대비 장점(표준화, 재사용성, 생태계)을 설명할 수 있다
- MCP 서버를 구축하여 커스텀 도구를 표준 프로토콜로 제공할 수 있다
- MCP 클라이언트에서 다양한 도구 서버를 연결하여 활용할 수 있다

**세부 학습 내용**:

| 시간 | 구분 | 내용 |
|------|------|------|
| 25분 | 이론 | MCP 개요: Function Calling의 한계(비표준, 재사용 어려움), MCP가 해결하는 문제, 아키텍처(Host, Client, Server, Transport) |
| 15분 | 이론 | MCP 도구 타입: Tools(실행), Resources(데이터), Prompts(템플릿), Sampling(LLM 호출), 각 타입의 활용 시나리오 |
| 10분 | 이론 | MCP 생태계: 공개 MCP 서버 마켓플레이스, 주요 도구 서버(파일시스템, DB, API), 보안 고려사항 |
| 40분 | 실습 | [Lab 7-1] MCP 서버 구축: Python으로 날씨 조회 + DB 검색 MCP 서버 구현, Transport 설정(stdio/SSE) |
| 30분 | 실습 | [Lab 7-2] MCP 클라이언트 연동: MCP 클라이언트에서 서버 연결, 도구 목록 조회, 도구 호출 테스트 |
| 30분 | 실습 | [Lab 7-3] MCP 도구 통합 봇: 여러 MCP 서버(파일, 웹검색, DB)를 연결한 통합 AI 어시스턴트 구현 |

**평가**: Lab 7-3 MCP 통합 봇 시연

---

### 모듈 7-2. Dify: 노코드 AI Agent 플랫폼 (2시간)

**학습 주제**: Dify를 활용한 빠른 AI 어플리케이션 구축
**학습 목표**:
- Dify 플랫폼의 구성요소와 워크플로우 빌더를 활용할 수 있다
- 코드 없이 RAG 기반 챗봇과 AI Agent를 구축할 수 있다
- 코드 기반 구현과 노코드 플랫폼의 트레이드오프를 판단할 수 있다

**세부 학습 내용**:

| 시간 | 구분 | 내용 |
|------|------|------|
| 15분 | 이론 | Dify 개요: 노코드 AI 플랫폼의 위치, 핵심 기능(챗봇, Agent, 워크플로우), 코드 vs 노코드 의사결정 |
| 15분 | 이론 | Dify 아키텍처: Knowledge Base(RAG), 워크플로우 노드, 외부 도구 연동, API 배포 |
| 30분 | 실습 | [Lab 7-4] Dify RAG 챗봇: Knowledge Base에 문서 업로드, RAG 기반 Q&A 챗봇 구축, 테스트 |
| 30분 | 실습 | [Lab 7-5] Dify 워크플로우 Agent: 워크플로우 빌더로 조건 분기 + 도구 호출 + 응답 생성 파이프라인 설계 |
| 30분 | 실습 | [Lab 7-6] Dify API 배포: 구축한 Agent를 API로 배포, 외부 어플리케이션에서 호출 테스트 |

**평가**: Lab 7-6 Dify Agent API 호출 성공 확인

---

### 모듈 7-3. 심화과정 종합 프로젝트 (2.5시간)

**학습 주제**: 심화과정 전체 기술을 통합한 실무급 프로젝트
**학습 목표**:
- 심화과정에서 학습한 기술 요소(Function Call, LangChain, RAG, GraphRAG, MAS, MCP, Dify)를 조합하여 실무 수준의 AI 시스템을 설계하고 구현할 수 있다
- 아키텍처 선택의 근거를 논리적으로 설명할 수 있다

**프로젝트 선택지** (1개 선택):

| 프로젝트 | 핵심 기술 | 난이도 |
|----------|-----------|--------|
| A. 사내 지식 관리 시스템 | RAG + GraphRAG + MCP 도구 통합 | 상 |
| B. 멀티에이전트 리서치 플랫폼 | MAS + 웹검색 RAG + 리포트 생성 | 상 |
| C. 노코드 + 코드 하이브리드 Agent | Dify 워크플로우 + MCP 서버 + Function Call | 중상 |

**세부 진행**:

| 시간 | 구분 | 내용 |
|------|------|------|
| 15분 | 안내 | 프로젝트 선택, 요구사항 확인, 아키텍처 설계 가이드라인 공유 |
| 20분 | 설계 | 아키텍처 설계서 작성: 시스템 구성도, 기술 선택 근거, 데이터 흐름 |
| 90분 | 실습 | [종합 Lab] 프로젝트 구현: 핵심 기능 구현 -> 통합 -> 테스트 -> 에러 핸들링 |
| 25분 | 발표 | 팀/개인별 결과물 시연, 아키텍처 설계 근거 발표, 상호 피드백 |

**평가**: 종합 프로젝트 완성도(동작 여부 40% + 아키텍처 설계 30% + 코드 품질 15% + 발표 15%)

---

### 모듈 7-4. Day 4 리뷰 및 심화과정 마무리 (1시간)

| 시간 | 구분 | 내용 |
|------|------|------|
| 10분 | 퀴즈 | Day 4 핵심 개념 확인 퀴즈 (8문항): MCP, Dify, 기술 선택 기준 |
| 20분 | 리뷰 | 심화과정 4일간 학습 내용 종합 정리, 기술 스택 로드맵 완성 |
| 15분 | 토론 | [커리어 적용 토론] 학습한 기술을 실무에 적용할 계획 공유, 학습 로드맵 수립 |
| 15분 | 마무리 | 수료 피드백 수집, 추가 학습 리소스 안내, 커뮤니티 연결 |

---

# 부록

## A. 평가 기준 총괄

### 기본과정 평가 배점

| 평가 항목 | 비중 | 세부 기준 |
|-----------|------|-----------|
| 일일 실습 결과물 | 50% | Lab별 코드 동작 여부(30%) + 코드 품질(10%) + 기한 내 제출(10%) |
| 종합 프로젝트 | 30% | 동작 여부(15%) + 기술 조합 적절성(10%) + 발표(5%) |
| 일일 퀴즈 | 20% | Day1(7%) + Day2(7%) + Day3(6%) |

### 심화과정 평가 배점

| 평가 항목 | 비중 | 세부 기준 |
|-----------|------|-----------|
| 일일 실습 결과물 | 50% | Lab별 코드 동작 여부(25%) + 코드 품질(15%) + 기한 내 제출(10%) |
| 종합 프로젝트 | 30% | 동작 여부(12%) + 아키텍처 설계(9%) + 코드 품질(5%) + 발표(4%) |
| 일일 퀴즈 | 20% | Day1(5%) + Day2(5%) + Day3(5%) + Day4(5%) |

---

## B. 실습 환경 요구사항

| 항목 | 최소 사양 | 권장 사양 |
|------|-----------|-----------|
| OS | Windows 10 / macOS 12 / Ubuntu 20.04 | Windows 11 / macOS 14 / Ubuntu 22.04 |
| Python | 3.10 이상 | 3.11 이상 |
| RAM | 8GB | 16GB (Local LLM 실습 시) |
| 저장 공간 | 10GB 여유 | 30GB 여유 (Local LLM 모델 포함) |
| GPU | 불필요 (Cloud API 중심) | NVIDIA GPU 8GB+ (Local LLM 가속) |
| 네트워크 | 안정적 인터넷 연결 필수 | 유선 네트워크 권장 |

---

## C. 사전 준비사항

### 기본과정 수강 전

1. Python 기초 문법 (변수, 함수, 클래스, 리스트/딕셔너리)
2. 터미널/명령 프롬프트 기본 사용법
3. OpenAI 또는 Anthropic API 키 발급 (사전 안내 메일 참조)
4. Python 3.10+ 설치 완료

### 심화과정 수강 전

1. 기본과정 수료 또는 동등 수준의 LLM API 사용 경험
2. REST API 개념 이해 (HTTP 메서드, JSON)
3. Docker 기본 설치 (Dify 실습용)
4. Neo4j Desktop 설치 (GraphRAG 실습용)

---

## D. 실무 적용 패턴 요약

| 패턴 | 조합 기술 | 적용 예시 |
|------|-----------|-----------|
| 문서 Q&A 시스템 | PDF 처리 + RAG + 멀티턴 대화 | 사내 규정 질의응답, 제품 매뉴얼 검색 |
| AI 회의록 자동화 | STT + 요약 + JSON 구조화 + TTS | 회의 녹음 -> 요약 -> 액션아이템 추출 -> 음성 브리핑 |
| 멀티에이전트 리서치봇 | MAS + 웹검색 RAG + 리포트 생성 | 시장 조사, 경쟁사 분석, 기술 트렌드 리포트 |
| MCP 도구 통합 | MCP 서버/클라이언트 + Function Call | 사내 시스템(DB, API, 파일) 표준 연동 |
| Dify 노코드 앱 | Dify 워크플로우 + Knowledge Base | 빠른 프로토타이핑, 비개발자 협업 AI 봇 |

---

## E. 추가 학습 리소스

| 주제 | 리소스 | 비고 |
|------|--------|------|
| LLM API | OpenAI API Docs, Anthropic API Docs | 공식 문서 |
| LangChain | LangChain 공식 문서, LangChain Cookbook | 최신 v0.3+ 기준 |
| RAG | LlamaIndex 공식 문서, Pinecone Learning Center | 심화 학습 |
| GraphRAG | Microsoft GraphRAG GitHub, Neo4j GenAI 가이드 | 고급 과정 |
| MCP | Anthropic MCP 공식 문서, MCP GitHub | 표준 스펙 |
| Dify | Dify 공식 문서, Dify GitHub | 셀프 호스팅 가이드 |
| Multi-Agent | LangGraph 공식 문서, CrewAI 문서 | 에이전트 프레임워크 |
